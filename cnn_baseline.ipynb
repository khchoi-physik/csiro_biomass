{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "83632c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, glob, random\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a4f2555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project_path :  /Users/k.choi/Documents/github/csiro_git\n",
      "data_path :  /Users/k.choi/Documents/github/csiro_git/data\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1785 entries, 0 to 1784\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   sample_id      1785 non-null   object \n",
      " 1   image_path     1785 non-null   object \n",
      " 2   Sampling_Date  1785 non-null   object \n",
      " 3   State          1785 non-null   object \n",
      " 4   Species        1785 non-null   object \n",
      " 5   Pre_GSHH_NDVI  1785 non-null   float64\n",
      " 6   Height_Ave_cm  1785 non-null   float64\n",
      " 7   target_name    1785 non-null   object \n",
      " 8   target         1785 non-null   float64\n",
      " 9   image_id       1785 non-null   object \n",
      "dtypes: float64(3), object(7)\n",
      "memory usage: 139.6+ KB\n",
      "data_df :  None\n"
     ]
    }
   ],
   "source": [
    "project_path    = \"/Users/k.choi/Documents/github/csiro_git\"\n",
    "data_path       = os.path.join(project_path, \"data\")\n",
    "img_path        = os.path.join(data_path, \"train\")\n",
    "# img_list        = glob.glob(os.path.join(img_path, \"*.jpg\")) \n",
    "# complete_df = pd.read_csv( project_path + '/stats/complete_df.csv')\n",
    "data_df = pd.read_csv(os.path.join(project_path, \"data\", \"train.csv\"))\n",
    "data_df['image_id'] = data_df['image_path'].apply(lambda x: Path(x).stem)\n",
    "\n",
    "print('project_path : ' , project_path)\n",
    "print('data_path : '    , data_path)\n",
    "# print('img_path : '     , img_path)\n",
    "# print('total number of images : ', len(img_list))\n",
    "print('data_df : ', data_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ff9f323",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -- -- Species -- -- \n",
      "0 ['Clover']\n",
      "1 ['Fescue']\n",
      "2 ['Fescue_CrumbWeed']\n",
      "3 ['Lucerne']\n",
      "4 ['Mixed']\n",
      "5 ['Phalaris']\n",
      "6 ['Phalaris_BarleyGrass_SilverGrass_SpearGrass_Clover_Capeweed']\n",
      "7 ['Phalaris_Clover']\n",
      "8 ['Phalaris_Clover_Ryegrass_Barleygrass_Bromegrass']\n",
      "9 ['Phalaris_Ryegrass_Clover']\n",
      "10 ['Ryegrass']\n",
      "11 ['Ryegrass_Clover']\n",
      "12 ['SubcloverDalkeith']\n",
      "13 ['SubcloverLosa']\n",
      "14 ['WhiteClover']\n",
      " -- -- State -- -- \n",
      "0 ['NSW']\n",
      "1 ['Tas']\n",
      "2 ['Vic']\n",
      "3 ['WA']\n"
     ]
    }
   ],
   "source": [
    "## Preprocessing converting categorical variables to numerical variables\n",
    "\n",
    "species_encoder = LabelEncoder()\n",
    "state_encoder   = LabelEncoder()\n",
    " \n",
    "data_df['Species']  = species_encoder.fit_transform(data_df['Species'])\n",
    "data_df['State']    = state_encoder.fit_transform(data_df['State'])\n",
    "\n",
    "print(' -- -- Species -- -- ')\n",
    "for i in np.unique(data_df['Species']): print(i, species_encoder.inverse_transform([i]) )\n",
    "print(' -- -- State -- -- ')\n",
    "for i in np.unique(data_df['State']): print(i, state_encoder.inverse_transform([i]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6bf76643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "357\n",
      "357\n",
      "357\n",
      "357\n",
      "357\n"
     ]
    }
   ],
   "source": [
    "meta_df = data_df.groupby('image_id').first()[['Sampling_Date', 'image_path', 'State', 'Species', 'Pre_GSHH_NDVI', 'Height_Ave_cm']].reset_index()\n",
    "\n",
    "\n",
    "dry_df      = data_df[data_df['target_name'] == 'Dry_Total_g'][['image_id', 'target']].copy(); print(len(dry_df))\n",
    "green_df    = data_df[data_df['target_name'] == 'Dry_Green_g'][['image_id', 'target']].copy(); print(len(green_df))\n",
    "dead_df     = data_df[data_df['target_name'] == 'Dry_Dead_g'][['image_id', 'target']].copy(); print(len(dead_df))\n",
    "clover_df   = data_df[data_df['target_name'] == 'Dry_Clover_g'][['image_id', 'target']].copy(); print(len(clover_df))\n",
    "gdm_df      = data_df[data_df['target_name'] == 'GDM_g'][['image_id', 'target']].copy(); print(len(gdm_df))\n",
    "\n",
    "dry_df      = dry_df.rename(columns={'target': 'Dry_Total_g'})\n",
    "green_df    = green_df.rename(columns={'target': 'Dry_Green_g'})\n",
    "dead_df     = dead_df.rename(columns={'target': 'Dry_Dead_g'})\n",
    "clover_df   = clover_df.rename(columns={'target': 'Dry_Clover_g'})\n",
    "gdm_df      = gdm_df.rename(columns={'target': 'GDM_g'})\n",
    "\n",
    "complete_df = pd.merge(meta_df, dry_df, on='image_id')\n",
    "complete_df = pd.merge(complete_df, green_df, on='image_id')\n",
    "complete_df = pd.merge(complete_df, dead_df, on='image_id')\n",
    "complete_df = pd.merge(complete_df, clover_df, on='image_id')\n",
    "complete_df = pd.merge(complete_df, gdm_df, on='image_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a40aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 121345\n",
    "\n",
    "train_df, valid_df = train_test_split(complete_df, test_size=0.2, random_state=random_state)\n",
    "\n",
    "excludes_cols = ['Dry_Total_g', 'Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g', 'image_id', 'Sampling_Date']\n",
    "target_cols   = ['Dry_Total_g', 'Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g']\n",
    "\n",
    "train_inputs = train_df.drop(columns= excludes_cols)\n",
    "train_targets = train_df[target_cols]\n",
    "\n",
    "valid_inputs = valid_df.drop(columns= excludes_cols)\n",
    "valid_targets = valid_df[target_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "320fc3a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['image_path', 'State', 'Species', 'Pre_GSHH_NDVI', 'Height_Ave_cm'], dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_inputs.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb289b95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Dry_Total_g', 'Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_targets.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d56e8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_csiro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
