{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20edd8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from skimage.feature import local_binary_pattern, graycomatrix, graycoprops\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import os, glob, random\n",
    "\n",
    "from src.get_features import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4eb2f98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project_path :  /Users/k.choi/Documents/github/csiro_git\n",
      "data_path :  /Users/k.choi/Documents/github/csiro_git/data\n",
      "img_path :  /Users/k.choi/Documents/github/csiro_git/data/train\n",
      "total number of images :  357\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1785 entries, 0 to 1784\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   sample_id      1785 non-null   object \n",
      " 1   image_path     1785 non-null   object \n",
      " 2   Sampling_Date  1785 non-null   object \n",
      " 3   State          1785 non-null   object \n",
      " 4   Species        1785 non-null   object \n",
      " 5   Pre_GSHH_NDVI  1785 non-null   float64\n",
      " 6   Height_Ave_cm  1785 non-null   float64\n",
      " 7   target_name    1785 non-null   object \n",
      " 8   target         1785 non-null   float64\n",
      " 9   image_id       1785 non-null   object \n",
      "dtypes: float64(3), object(7)\n",
      "memory usage: 139.6+ KB\n",
      "train_df :  None\n"
     ]
    }
   ],
   "source": [
    "project_path    = \"/Users/k.choi/Documents/github/csiro_git\"\n",
    "data_path       = os.path.join(project_path, \"data\")\n",
    "img_path        = os.path.join(data_path, \"train\")\n",
    "img_list        = glob.glob(os.path.join(img_path, \"*.jpg\"))\n",
    "train_df        = pd.read_csv(os.path.join(data_path, \"train.csv\"))\n",
    "train_df['image_id'] = train_df['image_path'].apply(lambda x: Path(x).stem)\n",
    "\n",
    "print('project_path : ' , project_path)\n",
    "print('data_path : '    , data_path)\n",
    "print('img_path : '     , img_path)\n",
    "print('total number of images : ', len(img_list))\n",
    "print('train_df : ', train_df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54210fba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "features extraction in progress: 100%|██████████| 357/357 [01:31<00:00,  3.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 30s, sys: 11.1 s, total: 1min 41s\n",
      "Wall time: 1min 31s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "features_list = []\n",
    "\n",
    "# for img_path in tqdm(selected_img_path, desc='features extraction in progress'):\n",
    "for img_path in tqdm(img_list, desc='features extraction in progress'):\n",
    "\n",
    "    try:\n",
    "        features = update_features(img_path)\n",
    "        features['image_id'] = Path(img_path).stem\n",
    "        features_list.append(features)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {img_path}: {e}\")\n",
    "        continue\n",
    "\n",
    "features_df = pd.DataFrame(features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55f1a276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 357 entries, 0 to 356\n",
      "Data columns (total 47 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   r_mean          357 non-null    float64\n",
      " 1   r_median        357 non-null    float64\n",
      " 2   r_std           357 non-null    float64\n",
      " 3   g_mean          357 non-null    float64\n",
      " 4   g_median        357 non-null    float64\n",
      " 5   g_std           357 non-null    float64\n",
      " 6   b_mean          357 non-null    float64\n",
      " 7   b_median        357 non-null    float64\n",
      " 8   b_std           357 non-null    float64\n",
      " 9   green_coverage  357 non-null    float64\n",
      " 10  hue_mean        357 non-null    float64\n",
      " 11  hue_std         357 non-null    float64\n",
      " 12  sat_mean        357 non-null    float64\n",
      " 13  sat_std         357 non-null    float64\n",
      " 14  val_mean        357 non-null    float64\n",
      " 15  val_std         357 non-null    float64\n",
      " 16  sobel_mean      357 non-null    float64\n",
      " 17  sobel_std       357 non-null    float64\n",
      " 18  canny_mean      357 non-null    float64\n",
      " 19  canny_std       357 non-null    float64\n",
      " 20  binary_mean     357 non-null    float64\n",
      " 21  binary_std      357 non-null    float64\n",
      " 22  lbp_mean        357 non-null    float64\n",
      " 23  lbp_std         357 non-null    float64\n",
      " 24  lbp_0           357 non-null    float64\n",
      " 25  lbp_1           357 non-null    float64\n",
      " 26  lbp_2           357 non-null    float64\n",
      " 27  lbp_3           357 non-null    float64\n",
      " 28  lbp_4           357 non-null    float64\n",
      " 29  lbp_5           357 non-null    float64\n",
      " 30  lbp_6           357 non-null    float64\n",
      " 31  lbp_7           357 non-null    float64\n",
      " 32  lbp_8           357 non-null    float64\n",
      " 33  lbp_9           357 non-null    float64\n",
      " 34  contrast        357 non-null    float64\n",
      " 35  dissimilarity   357 non-null    float64\n",
      " 36  homogeneity     357 non-null    float64\n",
      " 37  energy          357 non-null    float64\n",
      " 38  glcm_corre      357 non-null    float64\n",
      " 39  ASM             357 non-null    float64\n",
      " 40  entropy         357 non-null    float64\n",
      " 41  image_id        357 non-null    object \n",
      " 42  Sampling_Date   357 non-null    object \n",
      " 43  State           357 non-null    object \n",
      " 44  Species         357 non-null    object \n",
      " 45  Pre_GSHH_NDVI   357 non-null    float64\n",
      " 46  Height_Ave_cm   357 non-null    float64\n",
      "dtypes: float64(43), object(4)\n",
      "memory usage: 131.2+ KB\n",
      "357\n",
      "357\n",
      "357\n",
      "357\n",
      "357\n"
     ]
    }
   ],
   "source": [
    "metadata_df = train_df.groupby('image_id').first()[['Sampling_Date', 'State', 'Species', 'Pre_GSHH_NDVI', 'Height_Ave_cm']].reset_index()\n",
    "metadata_df = pd.merge(features_df, metadata_df, on='image_id', how='left')\n",
    "metadata_df.info()\n",
    "metadata_df.to_csv(os.path.join(project_path + '/stats', \"metadata_df.csv\"), index=False)\n",
    "\n",
    "dry_df      = train_df[train_df['target_name'] == 'Dry_Total_g'][['image_id', 'target']].copy(); print(len(dry_df))\n",
    "green_df    = train_df[train_df['target_name'] == 'Dry_Green_g'][['image_id', 'target']].copy(); print(len(green_df))\n",
    "dead_df     = train_df[train_df['target_name'] == 'Dry_Dead_g'][['image_id', 'target']].copy(); print(len(dead_df))\n",
    "clover_df   = train_df[train_df['target_name'] == 'Dry_Clover_g'][['image_id', 'target']].copy(); print(len(clover_df))\n",
    "gdm_df      = train_df[train_df['target_name'] == 'GDM_g'][['image_id', 'target']].copy(); print(len(gdm_df))\n",
    "\n",
    "dry_df      = dry_df.rename(columns={'target': 'Dry_Total_g'})\n",
    "green_df    = green_df.rename(columns={'target': 'Dry_Green_g'})\n",
    "dead_df     = dead_df.rename(columns={'target': 'Dry_Dead_g'})\n",
    "clover_df   = clover_df.rename(columns={'target': 'Dry_Clover_g'})\n",
    "gdm_df      = gdm_df.rename(columns={'target': 'GDM_g'})\n",
    "\n",
    "complete_df = pd.merge(metadata_df, dry_df, on='image_id')\n",
    "complete_df = pd.merge(complete_df, green_df, on='image_id')\n",
    "complete_df = pd.merge(complete_df, dead_df, on='image_id')\n",
    "complete_df = pd.merge(complete_df, clover_df, on='image_id')\n",
    "complete_df = pd.merge(complete_df, gdm_df, on='image_id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cb77b30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['r_mean', 'r_median', 'r_std', 'g_mean', 'g_median', 'g_std', 'b_mean',\n",
      "       'b_median', 'b_std', 'green_coverage', 'hue_mean', 'hue_std',\n",
      "       'sat_mean', 'sat_std', 'val_mean', 'val_std', 'sobel_mean', 'sobel_std',\n",
      "       'canny_mean', 'canny_std', 'binary_mean', 'binary_std', 'lbp_mean',\n",
      "       'lbp_std', 'lbp_0', 'lbp_1', 'lbp_2', 'lbp_3', 'lbp_4', 'lbp_5',\n",
      "       'lbp_6', 'lbp_7', 'lbp_8', 'lbp_9', 'contrast', 'dissimilarity',\n",
      "       'homogeneity', 'energy', 'glcm_corre', 'ASM', 'entropy', 'image_id',\n",
      "       'Sampling_Date', 'State', 'Species', 'Pre_GSHH_NDVI', 'Height_Ave_cm',\n",
      "       'Dry_Total_g', 'Dry_Green_g', 'Dry_Dead_g', 'Dry_Clover_g', 'GDM_g'],\n",
      "      dtype='object')\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 357 entries, 0 to 356\n",
      "Data columns (total 52 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   r_mean          357 non-null    float64\n",
      " 1   r_median        357 non-null    float64\n",
      " 2   r_std           357 non-null    float64\n",
      " 3   g_mean          357 non-null    float64\n",
      " 4   g_median        357 non-null    float64\n",
      " 5   g_std           357 non-null    float64\n",
      " 6   b_mean          357 non-null    float64\n",
      " 7   b_median        357 non-null    float64\n",
      " 8   b_std           357 non-null    float64\n",
      " 9   green_coverage  357 non-null    float64\n",
      " 10  hue_mean        357 non-null    float64\n",
      " 11  hue_std         357 non-null    float64\n",
      " 12  sat_mean        357 non-null    float64\n",
      " 13  sat_std         357 non-null    float64\n",
      " 14  val_mean        357 non-null    float64\n",
      " 15  val_std         357 non-null    float64\n",
      " 16  sobel_mean      357 non-null    float64\n",
      " 17  sobel_std       357 non-null    float64\n",
      " 18  canny_mean      357 non-null    float64\n",
      " 19  canny_std       357 non-null    float64\n",
      " 20  binary_mean     357 non-null    float64\n",
      " 21  binary_std      357 non-null    float64\n",
      " 22  lbp_mean        357 non-null    float64\n",
      " 23  lbp_std         357 non-null    float64\n",
      " 24  lbp_0           357 non-null    float64\n",
      " 25  lbp_1           357 non-null    float64\n",
      " 26  lbp_2           357 non-null    float64\n",
      " 27  lbp_3           357 non-null    float64\n",
      " 28  lbp_4           357 non-null    float64\n",
      " 29  lbp_5           357 non-null    float64\n",
      " 30  lbp_6           357 non-null    float64\n",
      " 31  lbp_7           357 non-null    float64\n",
      " 32  lbp_8           357 non-null    float64\n",
      " 33  lbp_9           357 non-null    float64\n",
      " 34  contrast        357 non-null    float64\n",
      " 35  dissimilarity   357 non-null    float64\n",
      " 36  homogeneity     357 non-null    float64\n",
      " 37  energy          357 non-null    float64\n",
      " 38  glcm_corre      357 non-null    float64\n",
      " 39  ASM             357 non-null    float64\n",
      " 40  entropy         357 non-null    float64\n",
      " 41  image_id        357 non-null    object \n",
      " 42  Sampling_Date   357 non-null    object \n",
      " 43  State           357 non-null    object \n",
      " 44  Species         357 non-null    object \n",
      " 45  Pre_GSHH_NDVI   357 non-null    float64\n",
      " 46  Height_Ave_cm   357 non-null    float64\n",
      " 47  Dry_Total_g     357 non-null    float64\n",
      " 48  Dry_Green_g     357 non-null    float64\n",
      " 49  Dry_Dead_g      357 non-null    float64\n",
      " 50  Dry_Clover_g    357 non-null    float64\n",
      " 51  GDM_g           357 non-null    float64\n",
      "dtypes: float64(48), object(4)\n",
      "memory usage: 145.2+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(complete_df.columns)\n",
    "print(complete_df.info())\n",
    "\n",
    "complete_df.to_csv(os.path.join(project_path + '/stats', \"complete_df.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47224e54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_csiro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
